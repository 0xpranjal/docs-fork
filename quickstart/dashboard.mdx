---
title: "Dashboard"
sidebarTitle: "Dashboard"
description: "Quickstart with the Vapi web dashboard."
---

### The Web Dashboard

<Frame caption="The Vapi web dashboard gives you a way to quickly create & manage assistants, provision phone numbers, & view conversation data.">
  <img src="/static/images/quickstart/dashboard/vapi-dashboard.png" />
</Frame>

One of the easiest ways to get started with Vapi is by using the web dashboard.

<Note>You can visit your dashboard by going to [dashboard.vapi.ai](https://dashboard.vapi.ai)</Note>

The web dashboard gives you the ability to:

- **view, create, & modify [assistants](/assistants)** associated with your account
- **provision & manage phone numbers** assistants can dial outbound from or receive inbound calls to
- **review conversation data** (such as audio recordings, call metadata, etc)
- **manage your [provider keys](/provider-keys)** (used in communication with external [TTS](/glossary#tts), LLM, & [STT](/glossary#stt) vendors)

Don’t feel overwhelmed by all of this information (& unfamiliar UI), we will be walking through the core necessities you need to get up and running in this guide.

<Tip>
  The web dashboard is only a convenience wrapper over the realtime call functionality of Vapi. The
  dashboard actually uses the [web SDK](/clients) beneath-the-hood to make calls.

So don’t feel limited by this UI, you can proceed to direct integration with one of [our SDKs](/clients) if you prefer.

</Tip>

## Vapi’s Pizzeria

In this guide we will be implementing a simple order-taking assistant at a pizza shop called “Vapi’s Pizzeria”.

Vapi’s has 3 types of menu items: `pizza`, `side`s, & `drink`s. Customers will be ordering 1 of each.

<Frame caption="Customers will order 3 items: 1 pizza, 1 side, & 1 drink. The assistant will handle the full order taking conversation.">
  <img src="/static/images/quickstart/vapis-pizzeria.png" />
</Frame>

## Assistant Setup

First we're going to set up our assistant in the dashboard. Once our assistant’s **transcriber**, **model**, & **voice** are set up, we can call it to place our order.

<Note>You can visit your dashboard at [dashboard.vapi.ai](https://dashboard.vapi.ai/)</Note>

### 0) Sign-up or Log-in to Vapi

If you haven't already signed-up, you're going to need an account before you can use the web dashboard. When you visit [dashboard.vapi.ai](https://dashboard.vapi.ai) you may see something like this:

<Frame>
  <img src="/static/images/quickstart/dashboard/auth-ui.png" />
</Frame>

Sign-up for an account (or log-in to your existing account) — you will then find yourself inside the web dashboard. It will look something like this:

<Frame caption="Your dashboard may look a bit different if you already have an account with assistants in it. The main idea is that we’re in the dashboard now.">
  <img src="/static/images/quickstart/dashboard/vapi-dashboard-post-signup.png" />
</Frame>

### 1) Create an Assistant

Now that you're in your dashboard, we're going to create an [assistant](/assistants).

Assistants are at the heart of how Vapi models AI voice agents — we will be setting certain properties on a new assistant to model an order-taking agent.

Once in the "Assistants" dashboard tab (you should be in it by-default after log-in), you will see a button to create a new assistant.

<Frame caption="Ensure you are in the 'Assistants' dashboard tab, then this button will allow you to begin the assistant creation flow.">
  <img src="/static/images/quickstart/dashboard/create-new-assistant-button.png" />
</Frame>

After clicking the create new assistant button, you will see a pop-up modal that asks you to pick a starter template. For our example we will start from a blank slate so choose the `Blank Template` option.

<Frame caption="Ensure you are in the 'Assistants' dashboard tab, then this button will allow you to begin the assistant creation flow.">
  <img src="/static/images/quickstart/dashboard/choose-blank-template.png" />
</Frame>

You will then be able to name your assistant — you can name it whatever you'd like (`Vapi’s Pizza Front Desk`, for example):

<Info>
  This name is only for internal labeling use. It is not an identifier, nor will the assistant be
  aware of this name.
</Info>

<Frame caption="Name your assistant.">
  <img src="/static/images/quickstart/dashboard/name-your-assistant.png" />
</Frame>

Once you have named your assistant, you can hit "Create" to create it. You will then see something like this:

<Frame caption="The assistant overview. You can edit your assistant’s transcriber, model, & voice — and edit other advanced configuration.">
  <img src="/static/images/quickstart/dashboard/assistant-created.png" />
</Frame>

This is the assistant overview view — it gives you the ability to edit different attributes about your assistant, as well as see **cost** & **latency** projection information for each portion of it’s voice pipeline (this is very important data to have handy when building out your assistants).

### 2) Model Setup

Now we’re going to set the "brains" of the assistant, the large language model. We're going to be using `GPT-4` (from [OpenAI](https://openai.com/)) for this demo (though you're free to use `GPT-3.5`, or any one of your favorite LLMs).

#### Set Your OpenAI Provider Key (optional)

Before we proceed, we will make sure we've configured our [provider key](/provider-keys) for OpenAI (this is just your OpenAI secret key).

<Note>
  You can see all of your provider keys in the "Provider Keys" dashboard tab. You can also go
  directly to [dashboard.vapi.ai/keys](https://dashboard.vapi.ai/keys).
</Note>

Vapi uses [provider keys](/provider-keys) you provide to communicate with LLM, TTS, & STT vendors on your behalf. It is most ideal that we set keys for the vendors we intend to use ahead of time.

<Tip>
  If Vapi detects that you are missing a provider key for a vendor (during assistant execution),
  Vapi will make the request for you with Vapi's own keys (& your account will be charged for the
  request at-cost).
</Tip>

<Frame caption="We set our provider key for OpenAI so Vapi can make requests to their API.">
  <img src="/static/images/quickstart/dashboard/model-provider-keys.png" />
</Frame>

While we're here it'd be ideal for you to go & set up provider keys for other providers you're familiar with & intend to use later.

#### First Message

Assistants can **optionally** be configured with a `First Message`. This first message will be spoken by your assistant when either:

- **A Web Call Connects:** when a web call is started with your assistant
- **An Inbound Call is Picked-up:** an [inbound call](/glossary#inbound-call) is picked-up & answered by your assistant
- **An Outbound Call is Dialed & Picked-up:** an [outbound call](/glossary#outbound-call) is dialed by your assistant & a person picks up

<Warning>
  Note that this first message cannot be interrupted & is guaranteed to be spoken. Certain use cases
  need a first message, while others do not.
</Warning>

<Note>
  You may see the term "web call" used here & there — which is an odd term on the face of it since
  the web involves no telephony. This is just a single term for us to name a conversational session,
  regardless of platform.
</Note>

For our use case, we will want a first message. It would be ideal for us to have a first message like this:

```text
Vappy’s Pizzeria speaking, how can I help you?
```

<Info>
  Some text-to-speech voices may struggle to pronounce 'Vapi' correctly, compartmentalizing it to be
  spoken letter by letter "V. A. P. I."

Some aspects of configuring your voice pipeline will require tweaks like this to get the target
behaviour you want.

</Info>

This will be spoken by the assistant when a web or inbound phone call is received (note that this is a fully inbound use case — people will be dialing into our agent, specifically only via phone).

#### System Prompt

We will now set the `System Prompt` for our assistant. If you're familiar with OpenAI's API, this is the first prompt in the message list that we feed our LLM (learn more about prompt engineering on the [OpenAI docs](https://platform.openai.com/docs/guides/prompt-engineering)).

The system prompt can be used to configure the context, role, personality, instructions and so on for the assistant. In our case, a system prompt like this will give us the behaviour we want:

```text
You are a voice assistant for Vappy’s Pizzeria,
a pizza shop located on the Internet.

Your job is to take the order of customers calling in. The menu has only 3 types
of items: pizza, sides, and drinks. There are no other types of items on the menu.

1) There are 3 kinds of pizza: cheese pizza, pepperoni pizza, and vegetarian pizza
(often called "veggie" pizza).
2) There are 3 kinds of sides: french fries, garlic bread, and chicken wings.
3) There are 2 kinds of drinks: soda, and water. (if a customer asks for a
brand name like "coca cola", just let them know that we only offer "soda")

Customers can only order 1 of each item. If a customer tries to order more
than 1 item within each category, politely inform them that only 1 item per
category may be ordered.

Customers must order 1 item from at least 1 category to have a complete order.
They can order just a pizza, or just a side, or just a drink.

Be sure to introduce the menu items, don't assume that the caller knows what
is on the menu (most appropriate at the start of the conversation).

If the customer goes off-topic or off-track and talks about anything but the
process of ordering, politely steer the conversation back to collecting their order.

Once you have all the information you need pertaining to their order, you can
end the conversation. You can say something like "Awesome, we'll have that ready
for you in 10-20 minutes." to naturally let the customer know the order has been
fully communicated.

It is important that you collect the order in an efficient manner (succinct replies
& direct questions). You only have 1 task here, and it is to collect the customers
order, then end the conversation.

- Be sure to be kind of funny and witty!
- Keep all your responses short and simple. Use casual language, phrases like "Umm...", "Well...", and "I mean" are preferred.
- This is a voice conversation, so keep your responses short, like in a real conversation. Don't ramble for too long.
```

You can copy & paste the above prompt into the `System Prompt` field. Now the model configuration for your assistant should look something like this:

<Frame caption="Note how our model provider is set to OpenAI & the model is set to GPT-4.">
  <img src="/static/images/quickstart/dashboard/assistant-model-set-up.png" />
</Frame>

### 3) Transcriber Setup

Remember that the transcriber is what turns user speech into processable text for our LLM. This is the first step in the end-to-end voice pipeline.

#### Set Your Deepgram Provider Key (optional)

We will be using [Deepgram](https://deepgram.com) (which provides blazing-fast & accurate Speech-to-Text) as our STT provider.

We will set our provider key for them in "Provider Keys":

<Frame>
  <img src="/static/images/quickstart/dashboard/transcriber-providers-keys.png" />
</Frame>

#### Set Transcriber

We will set the model to `Nova 2` & the language to `en` for English.

<Info>
  This is out of scope for this quickstart, but Vapi has full [multi-lingual
  support](/learn/multilingual/introduction) (if you need to support different user languages).
</Info>

Now your assistant's transcriber configuration should look something like this:

<Frame caption="Note how our transcriber is set to 'deepgram', the model is set to 'Nova 2', & the language is set to English.">
  <img src="/static/images/quickstart/dashboard/assistant-transcriber-config.png" />
</Frame>

<Tip>
  Transcription will be the least "custom" configuration we will touch. Once you solve
  Speech-to-text with incredibly low latency & high accuracy there isn't much else to configure
  (mainly speaker language).

Most customization in our pipeline will come from the model (LLM) & the voice (Text-to-speech).

</Tip>

### 4) Voice Setup

The final portion of the voice pipeline is turning LLM output-text into speech. This process is called "Text-to-speech" (or TTS for short).

We will be using a voice provider called [PlayHT](https://play.ht) (they have very conversational voices), & a voice provided by them labeled `Jennifer` (`female`, `en-US`).

<Info>
  You are free to use your favorite TTS voice platform here. [ElevenLabs](https://elevenlabs.io/) is
  another alternative — by now you should get the flow of plugging in vendors into Vapi (add
  provider key + pick provider in assistant config).

You can skip the next step(s) if you don't intend to use PlayHT.

</Info>

#### Set Your PlayHT Provider Key (optional)

If you haven't already, sign up for an account with PlayHT at [play.ht](https://play.ht). Since their flows are liable to change — you can just grab your `API Key` & `User ID` from them.

<Frame>
  <img src="/static/images/quickstart/dashboard/voice-provider-keys.png" />
</Frame>

#### Set Voice

You will want to select `playht` in the "provider" field, & `Jennifer` in the "voice" field. We will leave all of the other settings untouched.

<Frame caption="Each voice provider offers a host of settings you can modulate to customize voices. Here we will leave all the defaults alone.">
  <img src="/static/images/quickstart/dashboard/assistant-voice-config.png" />
</Frame>

### 5) Your Assistant Is Ready!

Our assistant is now ready to use for simple conversation.

For the sake of a quickstart, we only focused on the basics of setting the assistant's **model**, **transcriber**, & **voice** — but Vapi is capable of tooling your agent much further (we will investigate these elsewhere).

## Calling Your Assistant

Now that your assistant is fully setup & configured, we will want to contact it. There are 2 ways to "call in" to an assistant:

- **Over the Internet:** Network-enabled devices can contact Vapi via the Internet (i.e. web applications, mobile applications). No phone number is involved.
- **Via Telephony:** Phones can communicate to Vapi over a cellular network (i.e. phone call). One phone number dials to another phone number.

<Note>
  For our use case, it is most appropriate that customers will contact our assistant via an inbound
  phone call. Though, we will look at both ways of calling in.
</Note>

### Calling in the Dashboard

The quickest way to contact your new assistant is by simply using the call button on the assistant detail page:

<Frame caption="Call into your assistant via the dashboard.">
  <img src="/static/images/quickstart/dashboard/call-assistant-web-dashboard.png" />
</Frame>

<Tip>The dashboard uses the [web SDK](/clients) underneath to make web calls.</Tip>

This will start a web call with your assistant, you can now speak to it to order your pizza & sides!

### Calling in via Phone

Since our assistant is meant to take orders over the phone, we will want to set up [inbound calling](/phone_calling) to our assistant. We will need to do 2 things:

1. **provision a new phone number** to sit our agent behind (it will pick-up calls that come in — hence "inbound calling")
2. **place our agent behind that phone number**

<Info>
  If you already have your own phone numbers (purchased via Twilio or Vonage, etc), you can import
  them into Vapi for use. Learn more about [telephony](/phone_calling) on Vapi.
</Info>

#### Provision a Phone Number

The quickest way to secure a phone number for your assistant is to purchase a phone number directly through Vapi.

<Warning>
  Phone numbers purchased through Vapi will charge directly to your account — learn more about
  [phone calling](/phone_calling) & [our pricing](/pricing) before proceeding.
</Warning>

Navigate to the "Phone Numbers" section & click the "Buy number" button:

<Frame caption="Make sure you are in the 'Phone Numbers' dashboard tab.">
  <img src="/static/images/quickstart/dashboard/buy-a-phone-number.png" />
</Frame>

We will use the area code `415` for our phone number (these are area codes domestic to the US & Canada).

<Frame caption="Choose an area code for your phone number.">
  <img src="/static/images/quickstart/dashboard/buy-phone-number-modal.png" />
</Frame>

<Warning>
  Currently, only US & Canada phone numbers can be directly purchased through Vapi. Phone numbers in
  other regions must be imported, see our [phone calling](/phone_calling) guide.
</Warning>

Click "Buy", after purchasing a phone number you should see something like this:

<Frame caption="Here we can attach an assistant to the number for inbound calls (or perform an outbound call, with a select assistant).">
  <img src="/static/images/quickstart/dashboard/phone-number-config.png" />
</Frame>

Now we are ready to attach our order-taking assistant to the phone number to take orders!

#### Attach Your Assistant

In the `Inbound` area of the phone number detail view, select your assistant in the dropdown under `Assistant`.

<Frame caption="Your assistant will now pick-up calls made to this phone number.">
  <img src="/static/images/quickstart/dashboard/inbound-assistant-set.png" />
</Frame>

This will put your assistant behind the phone number for inbound calls. Your assistant is now ready to take calls.

#### Call the Number

You can now call the phone number & conversate with your assistant. Happy ordering!

<Tip>
  Your assistant won't yet be able to hang-up the phone at the end of the call. We will learn more
  about configuring call end behaviour in later guides.
</Tip>
